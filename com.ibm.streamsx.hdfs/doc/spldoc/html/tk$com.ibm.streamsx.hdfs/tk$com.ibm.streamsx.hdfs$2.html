<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="copyright" content="(C) Copyright 2005"/>
<meta name="DC.rights.owner" content="(C) Copyright 2005"/>
<meta name="DC.Type" content="reference"/>
<meta name="DC.Title" content="Using the toolkit to connect to HDFS outside of Bluemix"/>
<meta name="DC.Format" content="XHTML"/>
<meta name="DC.Identifier" content="spldoc_page"/>
<link rel="stylesheet" type="text/css" href="../../html/commonltr.css"/>
<link rel="stylesheet" type="text/css" href="../../html/spldoc.css"/>
<title>Using the toolkit to connect to HDFS outside of Bluemix</title>
</head>
<body id="spldoc_page">


<h1 class="title topictitle1">Using the toolkit to connect to HDFS outside of Bluemix</h1>

<div class="body refbody">
<div class="section">
<p class="p">
<a class="xref" href="../toolkits/toolkits.html">IBMStreams com.ibm.streamsx.hdfs Toolkit</a> &gt; <a class="xref" href="tk$com.ibm.streamsx.hdfs.html">com.ibm.streamsx.hdfs 3.5.1</a> &gt; Using the toolkit to connect to HDFS outside of Bluemix</p>

</div>


<div class="section">
<p class="p">These instructions apply if you are not connecting to HDFS in Bluemix.   To create applications that use the HDFS Toolkit, you must configure either Streams Studio or the SPL compiler to be aware of the location of the toolkit. 
</p>

</div>

<div class="section"><h2 class="title sectiontitle">Before you begin
</h2>

<div class="p">
<ul class="ul">
<li class="li"> Install IBM InfoSphere Streams.  Configure the product environment variables by entering the following command: 
<pre class="pre codeblock">
  source product-installation-root-directory/4.1.0.0/bin/streamsprofile.sh
</pre>

</li>

<li class="li"> Install a supported version of Hadoop. </li>

<li class="li"> Ensure that InfoSphere Streams has access to Hadoop libraries and configuration files  to allow streams processing applications to read and write to HDFS.   </li>

</ul>

</div>

</div>

<div class="section"><h2 class="title sectiontitle">About this task
</h2>

<p class="p">After the location of the toolkit is communicated to the compiler, the SPL artifacts that are specified in the toolkit can be used by an application. The application can include a use directive to bring the necessary namespaces into scope. Alternatively, you can fully qualify the operators that are provided by toolkit with their namespaces as prefixes.
</p>

</div>

<div class="section"><h2 class="title sectiontitle">Procedure
</h2>

<div class="p">
<ol class="ol">
<li class="li"> If InfoSphere Streams has access to the location where Hadoop is installed,     set the following environment variables:
<ul class="ul">
<li class="li"> For Apache HDFS, Cloudera, or Hortonworks Data Platform:
<ul class="ul">
<li class="li"> Set <strong class="ph b">HADOOP_HOME</strong> to <tt class="ph tt">Hadoop_Install_Directory</tt>. For example, <tt class="ph tt">/usr/lib/hadoop</tt>.</li>

<li class="li"> Set <strong class="ph b">JAVA_HOME</strong> to the location where Java is installed.</li>

</ul>
</li>

<li class="li"> For IBM InfoSphere BigInsights 3.x:
<ul class="ul">
<li class="li"> Set <strong class="ph b">BIGINSIGHTS_HOME</strong> to <tt class="ph tt">BigInsights_Install_Directory</tt>. For example, <tt class="ph tt">/opt/ibm/biginsights</tt>.</li>

<li class="li"> Set <strong class="ph b">HADOOP_HOME</strong> to <tt class="ph tt">BigInsights_Install_Directory/IHC</tt>. For example, <tt class="ph tt">/opt/ibm/biginsights/IHC</tt>.</li>

<li class="li"> Set <strong class="ph b">JAVA_HOME</strong> to the location where Java is installed.</li>

</ul>
</li>

<li class="li"> For IBM InfoSphere BigInsights 4.x:
<ul class="ul">
<li class="li"> Set <strong class="ph b">HADOOP_HOME</strong> to <tt class="ph tt">BigInsights_Install_Directory/hadoop</tt>. For example, <tt class="ph tt">/usr/iop/4.0.0.0/hadoop</tt>.</li>

<li class="li"> Set <strong class="ph b">JAVA_HOME</strong> to the location where Java is installed.   </li>

</ul>
</li>

</ul>
</li>

<li class="li"> If InfoSphere Streams does not have access to the location where Hadoop is installed,    copy the Hadoop library files to a location that is accessible to InfoSphere Streams    and set the appropriate environment variables.    The following list describes the Hadoop library files to copy:
<ul class="ul">
<li class="li"> For Apache HDFS, Cloudera, or Hortonworks Data Platform:
<ol class="ol" type="a">
<li class="li"> Copy <tt class="ph tt">/usr/lib/hadoop</tt> to the InfoSphere Streams cluster and place it in a directory on the cluster,         which is accessible to InfoSphere Streams.         <strong class="ph b">Note</strong>: When copying the directories, you must ensure that symbolic links are dereferenced,         otherwise the directory containing the <tt class="ph tt">core-site.xml</tt> file might not get copied to the InfoSphere Streams cluster.         On Linux, you can dereference a symbolic link by using the <strong class="ph b">-L</strong> flag. For example:
<pre class="pre codeblock">
   cp -Lr /usr/lib/hadoop /usr/lib/hadoop-hdfs /path-on-cluster
</pre>

</li>

<li class="li"> Copy <tt class="ph tt">/usr/lib/hadoop-hdfs</tt> to the InfoSphere Streams cluster and place it in a directory on the cluster,         which is accessible to InfoSphere Streams.</li>

</ol>
</li>

<li class="li"> For IBM InfoSphere BigInsights 3.x:
<ol class="ol" type="a">
<li class="li"> Copy <tt class="ph tt">BigInsights_Install_Directory/IHC</tt> to the InfoSphere Streams cluster and place it under a directory         on the cluster, which is accessible to InfoSphere Streams. For example, <tt class="ph tt">/home/Streams/BigInsights_Install_Directory/IHC</tt>.</li>

<li class="li"> Copy the<tt class="ph tt">BigInsights_Install_Directory/hadoop-conf</tt> directory to the InfoSphere Streams cluster         and place it under a directory on the cluster, which is accessible to InfoSphere Streams.         For example, <tt class="ph tt">/home/Streams/BigInsights_Install_Directory/hadoop-conf</tt></li>

</ol>
</li>

<li class="li"> For IBM InfoSphere BigInsights 4.x:
<ol class="ol" type="a">
<li class="li"> Copy <tt class="ph tt">BigInsights_Install_Directory/hadoop</tt> to the InfoSphere Streams cluster and place it under a directory         on the cluster, which is accessible to InfoSphere Streams. For example, <tt class="ph tt">/home/Streams/BigInsights_Install_Directory/hadoop</tt>.</li>

<li class="li"> Copy the <tt class="ph tt">BigInsights_Install_Directory/hadoop-hdfs</tt> directory to the InfoSphere Streams cluster         and place it under a directory on the cluster, which is accessible to InfoSphere Streams.         For example, <tt class="ph tt">/home/Streams/BigInsights_Install_Directory/hadoop-hdfs</tt>        </li>

</ol>
</li>

<li class="li"> For IBM InfoSphere BigInsights 3.x installed on GPFS:
<ul class="ul">
<li class="li"> <strong class="ph b">Important</strong>: If IBM InfoSphere BigInsights is installed on GPFS, you do not need to install InfoSphere Streams        on an IBM InfoSphere BigInsights data node. Use the <tt class="ph tt">webhdfs://hdfshost:webhdfsport</tt> schema in the URI        that you use to connect to GPFS.</li>

</ul>

<ol class="ol" type="a">
<li class="li"> Copy <tt class="ph tt">BigInsights_Install_Directory/IHC</tt> to the InfoSphere Streams cluster         and place it under a directory on the cluster, which is accessible to InfoSphere Streams.         For example, <tt class="ph tt">/home/Streams/BigInsights_Install_Directory/IHC</tt>.</li>

<li class="li"> Copy the <tt class="ph tt">BigInsights_Install_Directory/hadoop-conf</tt> directory to the InfoSphere Streams cluster         and place it under a directory on the cluster, which is accessible to InfoSphere Streams.         For example, <tt class="ph tt">/home/Streams/BigInsights_Install_Directory/hadoop-conf</tt></li>

<li class="li"> Copy <tt class="ph tt">BigInsights_Install_Directory/lib/biginsights-gpfs.jar</tt> to the InfoSphere Streams cluster         and place it under a directory on the cluster, which is accessible to InfoSphere Streams.         For example, <tt class="ph tt">/home/Streams/BigInsights_Install_Directory</tt>.       </li>

</ol>
</li>

<li class="li"> For IBM InfoSphere BigInsights 4.0.0.0 installed on GPFS:
<ul class="ul">
<li class="li"> The com.ibm.streamsx.hdfs toolkit does not support remote connections to a BigInsight 4.0.0.0 GPFS cluster. </li>

</ul>
</li>

</ul>
   The following list describes the environment variables to set when Hadoop and IBM InfoSphere BigInsights    libraries are copied to location that is accessible to InfoSphere Streams:
<ul class="ul">
<li class="li"> For Apache HDFS, Cloudera, or Hortonworks Data Platform:
<ul class="ul">
<li class="li"> Set <strong class="ph b">HADOOP_HOME</strong> to <tt class="ph tt">/home/Streams/hadoop</tt>.</li>

<li class="li"> Set <strong class="ph b">JAVA_HOME</strong> to the location where Java is installed.</li>

</ul>
</li>

<li class="li"> For IBM InfoSphere BigInsights 3.x:
<ul class="ul">
<li class="li"> Set <strong class="ph b">HADOOP_HOME</strong> to <tt class="ph tt">/home/Streams/biginsights/IHC</tt>.</li>

<li class="li"> Set <strong class="ph b">BIGINSIGHTS_HOME</strong> to <tt class="ph tt">/home/Streams/biginsights</tt>.</li>

<li class="li"> Set <strong class="ph b">JAVA_HOME</strong> to the location where Java is installed.</li>

</ul>
</li>

<li class="li"> For IBM InfoSphere BigInsights 4.x:
<ul class="ul">
<li class="li"> Set <strong class="ph b">HADOOP_HOME</strong> to <tt class="ph tt">/home/Streams/biginsights/hadoop</tt>.</li>

<li class="li"> Set <strong class="ph b">JAVA_HOME</strong> to the location where Java is installed.     </li>

</ul>
</li>

<li class="li"> IBM InfoSphere BigInsights 3.x installed on GPFS:
<ul class="ul">
<li class="li"> Set <strong class="ph b">HADOOP_HOME</strong> to <tt class="ph tt">/opt/ibm/biginsights/IHC/</tt>.</li>

<li class="li"> Set <strong class="ph b">BIGINSIGHTS_HOME</strong> to <tt class="ph tt">/opt/ibm/biginsights</tt>.</li>

<li class="li"> Set <strong class="ph b">JAVA_HOME</strong> to the location where Java is installed.        </li>

</ul>
</li>

</ul>
</li>

<li class="li"> Configure the SPL compiler to find the toolkit root directory. Use one of the following methods:
<ul class="ul">
<li class="li"> Set the <strong class="ph b">STREAMS_SPLPATH</strong> environment variable to the root directory of a toolkit     or multiple toolkits (with : as a separator).  For example:
<pre class="pre codeblock">
export STREAMS_SPLPATH=$STREAMS_INSTALL/toolkits/com.ibm.streamsx.hdfs
</pre>

</li>

<li class="li"> Specify the <strong class="ph b">-t</strong> or <strong class="ph b">--spl-path</strong> command parameter when you run the <strong class="ph b">sc</strong> command. For example:
<pre class="pre codeblock">
sc -t $STREAMS_INSTALL/toolkits/com.ibm.streamsx.hdfs -M MyMain
</pre>

    where MyMain is the name of the SPL main composite.     <strong class="ph b">Note</strong>: These command parameters override the <strong class="ph b">STREAMS_SPLPATH</strong> environment variable.</li>

<li class="li"> Add the toolkit location in InfoSphere Streams Studio.</li>

</ul>
</li>

<li class="li"> Develop your application. To avoid the need to fully qualify the operators, add a use directive in your application. 
<ul class="ul">
<li class="li"> For example, you can add the following clause in your SPL source file:
<pre class="pre codeblock">
use com.ibm.streamsx.hdfs::*;
</pre>

    You can also specify a use clause for individual operators by replacing the asterisk (*) with the operator name. For example: 
<pre class="pre codeblock">
use com.ibm.streamsx.hdfs::HDFS2FileSink;
</pre>

</li>

</ul>
</li>

<li class="li"> If IBM InfoSphere BigInsights 3.x or 4.x is installed on GPFS:
<ul class="ul">
<li class="li"> To access GPFS locally, set the <tt class="ph tt">fs.defaultFS</tt> option in the <tt class="ph tt">core-site.xml</tt> configuration file to <tt class="ph tt">gpfs:///</tt>.</li>

<li class="li"> To access GPFS remotely (<strong class="ph b">only applies to BigInsights 3.x</strong>), modify the <tt class="ph tt">core-site.xml</tt> that you have copied over from the remote system.       Set the <tt class="ph tt">fs.default.FS</tt> option in the <tt class="ph tt">core-site.xml</tt> configuration file to <tt class="ph tt">webhdfs://hdfshost:webhdfsport</tt>.       For example, <tt class="ph tt">webhdfs://myhdfshost:14000</tt>.      Ensure that the user is set up to access the file system by using the webhdfs schema.</li>

</ul>
</li>

<li class="li"> To read and write to HDFS, specify a uniform resource identifier (URI) to connect to HDFS.    You can specify the URI in one of the following ways:
<ul class="ul">
<li class="li"> Specify a value for the <tt class="ph tt">fs.defautlFS</tt> or <tt class="ph tt">fs.default.name</tt> option in the <tt class="ph tt">core-site.xml</tt> HDFS configuration file.      By default, the operators look for the <tt class="ph tt">core-site.xml</tt> file in the following directories:
<ul class="ul">
<li class="li"> <tt class="ph tt">$HADOOP_HOME/../hadoop-conf</tt></li>

<li class="li"> <tt class="ph tt">$HADOOP_HOME/etc/hadoop</tt></li>

<li class="li"> <tt class="ph tt">$HADOOP_HOME/conf</tt></li>

<li class="li"> <tt class="ph tt">$HADOOP_HOME/share/hadoop/hdfs/*</tt></li>

<li class="li"> <tt class="ph tt">$HADOOP_HOME/share/hadoop/common/*</tt></li>

<li class="li"> <tt class="ph tt">$HADOOP_HOME/share/hadoop/common/lib/*</tt></li>

<li class="li"> <tt class="ph tt">$HADOOP_HOME/lib/*</tt></li>

<li class="li"> <tt class="ph tt">$HADOOP_HOME/*</tt></li>

</ul>
     Tip: To specify a different location for the HDFS configuration files, set the <strong class="ph b">configPath</strong> operator parameter.</li>

<li class="li"> Specify a value for the <strong class="ph b">hdfsUri</strong> operator parameter.</li>

</ul>
</li>

<li class="li"> Build your application.  You can use the <strong class="ph b">sc</strong> command or Streams Studio.  </li>

<li class="li"> Start the InfoSphere Streams instance. </li>

<li class="li"> Run the application. You can submit the application as a job by using the <strong class="ph b">streamtool submitjob</strong> command or by using Streams Studio. </li>

</ol>

</div>

</div>

</div>


</body>
</html>